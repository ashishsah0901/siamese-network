{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f77b672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D, Dense, Lambda\n",
    "from keras import backend as K\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e41aafa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputs = Input((64, 64, 1))\n",
    "    x = Conv2D(96, (11, 11), padding=\"same\", activation=\"relu\")(inputs)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(256, (5, 5), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(384, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    pooledOutput = GlobalAveragePooling2D()(x)\n",
    "    pooledOutput = Dense(1024)(pooledOutput)\n",
    "    outputs = Dense(128)(pooledOutput)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f1871d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = create_model()\n",
    "imgA = Input(shape=(64, 64, 1))\n",
    "imgB = Input(shape=(64, 64, 1))\n",
    "featA = feature_extractor(imgA)\n",
    "featB = feature_extractor(imgB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "880d2634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vectors):\n",
    "    (featA, featB) = vectors\n",
    "    sum_squared = K.sum(K.square(featA - featB), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_squared, K.epsilon()))\n",
    "\n",
    "distance = Lambda(euclidean_distance)([featA, featB])\n",
    "outputs = Dense(1, activation=\"sigmoid\")(distance)\n",
    "model = Model(inputs=[imgA, imgB], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8a289db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "929ff667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_image_pairs(images_dataset, labels_dataset):\n",
    "    unique_labels = np.unique(labels_dataset)\n",
    "    label_wise_indices = dict()\n",
    "    for label in unique_labels:\n",
    "        label_wise_indices.setdefault(label,\n",
    "                                      [index for index, curr_label in enumerate(labels_dataset) if label == curr_label])\n",
    "    \n",
    "    pair_images = []\n",
    "    pair_labels = []\n",
    "    for index, image in enumerate(images_dataset):\n",
    "        pos_indices = label_wise_indices.get(labels_dataset[index])\n",
    "        pos_image = images_dataset[np.random.choice(pos_indices)]\n",
    "        pair_images.append((image, pos_image))\n",
    "        pair_labels.append(1)\n",
    "\n",
    "        neg_indices = np.where(labels_dataset != labels_dataset[index])\n",
    "        neg_image = images_dataset[np.random.choice(neg_indices[0])]\n",
    "        pair_images.append((image, neg_image))\n",
    "        pair_labels.append(0)\n",
    "    return np.array(pair_images), np.array(pair_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c14fec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data = fetch_olivetti_faces()\n",
    "images_dataset = image_data.images\n",
    "labels_dataset = image_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54892f97",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 327s 26s/step - loss: 0.6951 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 281s 24s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 279s 23s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 270s 22s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 274s 23s/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 293s 25s/step - loss: 0.6936 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 305s 24s/step - loss: 0.6936 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 277s 23s/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 290s 24s/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 287s 24s/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 285s 24s/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 288s 24s/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 276s 23s/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 270s 22s/step - loss: 0.6930 - accuracy: 0.4972 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 270s 22s/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 268s 22s/step - loss: 0.6931 - accuracy: 0.4931 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 269s 22s/step - loss: 0.6935 - accuracy: 0.5028 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 278s 23s/step - loss: 0.6930 - accuracy: 0.5056 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 269s 22s/step - loss: 0.6932 - accuracy: 0.5042 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 265s 22s/step - loss: 0.6938 - accuracy: 0.5250 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 262s 22s/step - loss: 0.6932 - accuracy: 0.4583 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 262s 22s/step - loss: 0.6933 - accuracy: 0.4819 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 262s 22s/step - loss: 0.6935 - accuracy: 0.4944 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 263s 22s/step - loss: 0.6934 - accuracy: 0.4778 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 262s 22s/step - loss: 0.6932 - accuracy: 0.4736 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 263s 22s/step - loss: 0.6931 - accuracy: 0.5028 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 242s 20s/step - loss: 0.6932 - accuracy: 0.5042 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 241s 20s/step - loss: 0.6935 - accuracy: 0.4792 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 242s 20s/step - loss: 0.6930 - accuracy: 0.5167 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 242s 20s/step - loss: 0.6932 - accuracy: 0.5167 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 245s 20s/step - loss: 0.6936 - accuracy: 0.4875 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 248s 21s/step - loss: 0.6934 - accuracy: 0.5083 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 248s 21s/step - loss: 0.6931 - accuracy: 0.4986 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 248s 21s/step - loss: 0.6931 - accuracy: 0.4986 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 248s 21s/step - loss: 0.6933 - accuracy: 0.5278 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 248s 21s/step - loss: 0.6931 - accuracy: 0.5319 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 251s 21s/step - loss: 0.6929 - accuracy: 0.5042 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 251s 21s/step - loss: 0.6934 - accuracy: 0.5153 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 249s 21s/step - loss: 0.6925 - accuracy: 0.5069 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 252s 21s/step - loss: 0.6934 - accuracy: 0.5014 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 253s 21s/step - loss: 0.6929 - accuracy: 0.5306 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 248s 21s/step - loss: 0.6941 - accuracy: 0.4833 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 251s 21s/step - loss: 0.6940 - accuracy: 0.4903 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 252s 21s/step - loss: 0.6928 - accuracy: 0.5028 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 255s 21s/step - loss: 0.6926 - accuracy: 0.4931 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 256s 21s/step - loss: 0.6920 - accuracy: 0.5222 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 249s 21s/step - loss: 0.6935 - accuracy: 0.5167 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 249s 21s/step - loss: 0.6918 - accuracy: 0.5153 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 258s 21s/step - loss: 0.6948 - accuracy: 0.5194 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 260s 22s/step - loss: 0.6935 - accuracy: 0.5125 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 265s 22s/step - loss: 0.6928 - accuracy: 0.5264 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 266s 22s/step - loss: 0.6930 - accuracy: 0.5444 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 268s 22s/step - loss: 0.6932 - accuracy: 0.5319 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 266s 22s/step - loss: 0.6934 - accuracy: 0.4833 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 264s 22s/step - loss: 0.6935 - accuracy: 0.4889 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 265s 22s/step - loss: 0.6939 - accuracy: 0.4792 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 286s 24s/step - loss: 0.6926 - accuracy: 0.5181 - val_loss: 0.6933 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "12/12 [==============================] - 279s 23s/step - loss: 0.6933 - accuracy: 0.5056 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 273s 23s/step - loss: 0.6935 - accuracy: 0.5097 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 276s 23s/step - loss: 0.6930 - accuracy: 0.5069 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 272s 23s/step - loss: 0.6933 - accuracy: 0.4833 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 275s 23s/step - loss: 0.6931 - accuracy: 0.4931 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 277s 23s/step - loss: 0.6932 - accuracy: 0.4889 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 299s 25s/step - loss: 0.6933 - accuracy: 0.5083 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 303s 25s/step - loss: 0.6933 - accuracy: 0.5028 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 289s 24s/step - loss: 0.6928 - accuracy: 0.5194 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 284s 24s/step - loss: 0.6925 - accuracy: 0.5222 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 282s 23s/step - loss: 0.6940 - accuracy: 0.4722 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 278s 23s/step - loss: 0.6937 - accuracy: 0.5042 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 276s 23s/step - loss: 0.6932 - accuracy: 0.4958 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 273s 23s/step - loss: 0.6931 - accuracy: 0.4931 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 276s 23s/step - loss: 0.6933 - accuracy: 0.5236 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 279s 23s/step - loss: 0.6931 - accuracy: 0.4889 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 277s 23s/step - loss: 0.6932 - accuracy: 0.5097 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 278s 23s/step - loss: 0.6939 - accuracy: 0.5042 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 306s 26s/step - loss: 0.6929 - accuracy: 0.5042 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 310s 26s/step - loss: 0.6930 - accuracy: 0.5181 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 312s 26s/step - loss: 0.6930 - accuracy: 0.4875 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 305s 25s/step - loss: 0.6938 - accuracy: 0.4806 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 322s 26s/step - loss: 0.6936 - accuracy: 0.4736 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 284s 24s/step - loss: 0.6934 - accuracy: 0.4778 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 281s 23s/step - loss: 0.6930 - accuracy: 0.4861 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 278s 23s/step - loss: 0.6934 - accuracy: 0.4861 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 279s 23s/step - loss: 0.6933 - accuracy: 0.5306 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 278s 23s/step - loss: 0.6929 - accuracy: 0.5056 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 280s 23s/step - loss: 0.6934 - accuracy: 0.4889 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 275s 23s/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 271s 23s/step - loss: 0.6934 - accuracy: 0.5111 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 276s 23s/step - loss: 0.6940 - accuracy: 0.4764 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 273s 23s/step - loss: 0.6933 - accuracy: 0.4972 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 270s 22s/step - loss: 0.6929 - accuracy: 0.5347 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 272s 23s/step - loss: 0.6925 - accuracy: 0.5111 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 273s 23s/step - loss: 0.6942 - accuracy: 0.4681 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 275s 23s/step - loss: 0.6938 - accuracy: 0.4750 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 272s 23s/step - loss: 0.6934 - accuracy: 0.4889 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 279s 23s/step - loss: 0.6931 - accuracy: 0.5208 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 278s 23s/step - loss: 0.6933 - accuracy: 0.4972 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 278s 23s/step - loss: 0.6934 - accuracy: 0.4833 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 276s 23s/step - loss: 0.6938 - accuracy: 0.4778 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 280s 23s/step - loss: 0.6934 - accuracy: 0.4917 - val_loss: 0.6934 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "images_pair, labels_pair = generate_train_image_pairs(images_dataset, labels_dataset)\n",
    "history = model.fit([images_pair[:, 0], images_pair[:, 1]], labels_pair[:],validation_split=0.1,batch_size=64,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e218442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_image_pairs(images_dataset, labels_dataset, image):\n",
    "    unique_labels = np.unique(labels_dataset)\n",
    "    label_wise_indices = dict()\n",
    "    for label in unique_labels:\n",
    "        label_wise_indices.setdefault(label, [index for index, curr_label in enumerate(labels_dataset) if label == curr_label])\n",
    "    pair_images = []\n",
    "    pair_labels = []\n",
    "    for label, indices_for_label in label_wise_indices.items():\n",
    "        test_image = images_dataset[np.random.choice(indices_for_label)]\n",
    "        pair_images.append((image, test_image))\n",
    "        pair_labels.append(label)\n",
    "    return np.array(pair_images), np.array(pair_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad597d30",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 714ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 128ms/step\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "1/1 [==============================] - 0s 125ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 133ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 147ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 148ms/step\n",
      "1/1 [==============================] - 0s 118ms/step\n",
      "1/1 [==============================] - 0s 143ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 135ms/step\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "1/1 [==============================] - 0s 130ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n",
      "1/1 [==============================] - 0s 141ms/step\n"
     ]
    }
   ],
   "source": [
    "image = images_dataset[92] # a random image as test image\n",
    "test_image_pairs, test_label_pairs = generate_test_image_pairs(images_dataset, labels_dataset, image)\n",
    "for index, pair in enumerate(test_image_pairs):\n",
    "    pair_image1 = np.expand_dims(pair[0], axis=-1)\n",
    "    pair_image1 = np.expand_dims(pair_image1, axis=0)\n",
    "    pair_image2 = np.expand_dims(pair[1], axis=-1)\n",
    "    pair_image2 = np.expand_dims(pair_image2, axis=0)\n",
    "    prediction = model.predict([pair_image1, pair_image2])[0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
